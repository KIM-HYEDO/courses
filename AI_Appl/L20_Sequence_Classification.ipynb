{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L20_Sequence_Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPGTfEs2V8PpBR8A1z1gh9Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Fy2_q1yA_eY2"},"source":["# Sequence Classification\n"," "]},{"cell_type":"markdown","metadata":{"id":"kFWSw3mPzCd3"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"ePyjL-fEA4As","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638863317529,"user_tz":-540,"elapsed":18442,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"ae8b2352-6ec0-4891-83c1-124272a4b201"},"source":["import os\n","import torch\n","import torch.nn as nn\n","from torchtext.legacy import data, datasets \n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","# parameters\n","batch_size = 64\n","learning_rate = 0.001\n","training_epochs = 5"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","cuda\n"]}]},{"cell_type":"markdown","metadata":{"id":"c-W8ykrC5Pz4"},"source":["### 1 Dataset\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kh5IsVGt5ba4","executionInfo":{"status":"ok","timestamp":1638863458022,"user_tz":-540,"elapsed":44056,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"3c408e05-a0a2-4df5-fbca-849cdbb58a3f"},"source":["# IMDB Dataset\n","\n","# data.Field 설명 #\n","# sequential인자 : TEXT는 Sequential 데이터라 True, Lable은 비Sequential이라 False로 설정\n","# batch_first : Batch를 우선시 하여, Tensor 크기를 (BATCH_SIZE, 문장의 최대 길이)로 설정\n","# lower : 소문자 전환 인자\n","\n","TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n","LABEL = data.Field(sequential=False, batch_first=True)\n","trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n","\n","# data.Field.build_vocab() 라이브러리\n","# 문장 내 단어와 Integer index 를 매칭시키는 단어장(vocab)을 생성 == 워드 임베딩을 위한 Vocab 생성\n","# <UNK> = 0, <PAD> = 1 토큰도 추가.\n","# min_freq : 최소 5번 이상 등장한 단어들만 사전에 담겠다는 것. \n","# 5번 미만으로 등장하는 단어는 UNK라는 토큰으로 대체\n","\n","TEXT.build_vocab(trainset, min_freq=5)# TEXT 데이터를 기반으로 Vocab 생성\n","LABEL.build_vocab(trainset)# LABEL 데이터를 기반으로 Vocab 생성\n","\n","# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n","trainset, valset = trainset.split(split_ratio=0.8)\n","# 매 배치마다 비슷한 길이에 맞춰 줄 수 있도록 iterator 정의\n","train_iter, val_iter, test_iter = data.BucketIterator.splits(\n","        (trainset, valset, testset), batch_size=batch_size,\n","        shuffle=True, repeat=False)\n","\n","vocab_size = len(TEXT.vocab)\n","n_classes = 2 # Positive, Negative Class가 두 개\n","\n","print(\"[TrainSet]: %d [ValSet]: %d [TestSet]: %d [Vocab]: %d [Classes] %d\"\n","      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading aclImdb_v1.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 84.1M/84.1M [00:02<00:00, 41.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["[TrainSet]: 20000 [ValSet]: 5000 [TestSet]: 25000 [Vocab]: 46159 [Classes] 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"SH2RX5pEBB0H"},"source":["### 2 RNN model\n","* Layer 설계\n","  + Layer 1\n","    - Embedding Layer\n","    - Input size = n_Vocabs = 46159\n","    - Output size = Embedding size\n","  + Layer 2\n","    - GRU Layer\n","    - Input size = Embedding size\n","    - Output size = Hidden size\n","    - Dropout = 0.2\n","  + Layer 3\n","    - Linear Layer\n","    - Input size = Hidden size\n","    - Output size = n_Classes = 2"]},{"cell_type":"code","metadata":{"id":"HL2ZwVjWBCw7","executionInfo":{"status":"ok","timestamp":1638863499672,"user_tz":-540,"elapsed":270,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}}},"source":["class BasicGRU(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n","        super(BasicGRU, self).__init__()\n","        self.n_layers = n_layers # 일반적으로는 2\n","\n","        #n_vocab : Vocab 안에 있는 단어의 개수, embed_dim : 임베딩 된 단어 텐서가 갖는 차원 값(dimension)\n","        self.embed = nn.Embedding(n_vocab, embed_dim)\n","\n","        # hidden vector의 dimension과 dropout 정의\n","        self.hidden_dim = hidden_dim\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        #앞에서 정의한 하이퍼 파라미터를 넣어 GRU 정의\n","        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n","                          num_layers=self.n_layers,\n","                          batch_first=True)\n","        \n","        #Input: GRU의 hidden vector(context), Output : Class probability vector\n","        self.out = nn.Linear(self.hidden_dim, n_classes)\n","\n","    def forward(self, x):\n","        # Input data: 한 batch 내 모든 영화 평가 데이터\n","        \n","        x = self.embed(x)# 영화 평 임베딩\n","        x, _ = self.gru(x)  # [i, b, h] 출력값 :  (batch_size, 입력 x의 길이, hidden_dim)\n","\n","        # h_t : Batch 내 모든 sequential hidden state vector의 제일 마지막 토큰을 내포한 (batch_size, 1, hidden_dim)형태의 텐서 추출\n","        # 다른 의미로 영화 리뷰 배열들을 압축한 hidden state vector\n","        h_t = x[:,-1,:]\n","\n","        self.dropout(h_t)# dropout 설정 후, \n","\n","        # linear layer의 입력으로 주고, 각 클래스 별 결과 logit을 생성.\n","        out = self.out(h_t)  # [b, h] -> [b, o]\n","        return out"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjPX7b5A6PA-"},"source":["### 3 학습하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6XeYPhI6Tig","executionInfo":{"status":"ok","timestamp":1638863827118,"user_tz":-540,"elapsed":322581,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"8ea18e60-940c-47d0-d9f3-a7f32897cda2"},"source":["# contruct model\n","model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n","\n","# define cost/loss & optimizer\n","criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# train\n","for epoch in range(training_epochs):\n","  avg_cost = 0\n","  for batch in train_iter:\n","    X, Y = batch.text.to(device), batch.label.to(device)\n","    Y.data.sub_(1)\n","    optimizer.zero_grad()\n","    hypothesis = model(X)\n","    cost = criterion(hypothesis, Y)\n","    cost.backward()\n","    optimizer.step()\n","    avg_cost += cost / batch_size\n","  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n","print('Learning Finished!')\n","\n","# model save\n","torch.save(model.state_dict(), '/content/drive/MyDrive/model_s1.pt')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch:    1] cost = 3.41189408\n","[Epoch:    2] cost = 3.39696717\n","[Epoch:    3] cost = 3.39243889\n","[Epoch:    4] cost = 3.38118362\n","[Epoch:    5] cost = 3.14284444\n","Learning Finished!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoemsR1Qzsze","executionInfo":{"status":"ok","timestamp":1638863984559,"user_tz":-540,"elapsed":2053,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"8ea985a8-80b9-427c-946d-f7f2350b7b61"},"source":["# model load\n","model_new = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n","model_new.load_state_dict(torch.load('/content/drive/MyDrive/model_s1.pt'))\n","\n","corrects = 0\n","for batch in val_iter:\n","  x,y = batch.text.to(device), batch.label.to(device)\n","  y.data.sub_(1)\n","  hypothesis = model_new(x)\n","  corrects += (hypothesis.max(1)[1].view(y.size()).data == y.data).sum() \n","\n","print('accuracy = ', corrects/len(val_iter.dataset)*100.0)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy =  tensor(77.8000, device='cuda:0')\n"]}]},{"cell_type":"markdown","metadata":{"id":"hc6TPzluWB1M"},"source":["### 4 Assignment\n","### a) 아래 예제 코드를 이용해 텍스트 입력의 숫자 변환 과정을 체크한다\n","### b) testset의 임의 입력을 LongTensor로 변환해 학습 완료된 모델에 입력해보고, 결과가 어떠한지 체크한다 (하단의 출력 결과를 참조)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie20dbcX51N5","executionInfo":{"status":"ok","timestamp":1638782255227,"user_tz":-540,"elapsed":308,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"37dc3e0e-c8c9-48b2-bbaf-bdd45fc573b2"},"source":["input_text = testset[3].text\n","print(input_text)\n","print(TEXT.vocab[input_text[0]])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'mystery', 'and', 'its', 'solution', 'was', 'a', 'great', 'noir', 'conceit.', 'i', 'do', 'have', 'some', 'questions', 'though,', 'maybe', 'i', \"wasn't\", 'paying', 'enough', 'attention.<br', '/><br', '/>who', 'killed', 'the', 'neighbor', 'and', 'why?', 'who', 'killed', 'the', 'replacement', 'girl', 'and', 'why?<br', '/><br', '/>and', 'some', 'minor', 'quibbles,', 'they', 'should', 'have', 'shown', 'the', 'stopoff', 'at', 'the', 'hotel', 'for', 'the', 'switch.', 'not', 'that', 'they', 'should', 'have', 'shown', 'the', 'switch,', 'but', 'they', 'should', 'have', 'shown', 'jim', 'and', 'the', 'girl', 'going', 'in', 'the', 'hotel,', 'jim', 'going', 'to', 'the', 'bathroom,', 'coming', 'out', 'and', 'being', 'told', 'by', 'the', 'bartender', 'that', 'his', 'girlfriend', 'went', 'to', 'the', 'car', 'without', 'him.<br', '/><br', '/>then,', 'jim', 'getting', 'back', 'in', 'the', 'car', 'and', 'seeing', 'the', 'sleeping', 'woman,', 'and', 'little', 'girl', 'in', 'his', 'back', 'seat.<br', '/><br', '/>this', 'would', 'have', 'given', 'the', 'viewer', 'a', 'sporting', 'chance', 'at', 'figuring', 'out', 'the', 'solution.<br', '/><br', '/>i', 'wish', 'i', 'taped', 'it', 'though,', \"i'd\", 'like', 'to', 'see', 'it', 'again.']\n","2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXFvDKMOCed6","executionInfo":{"status":"ok","timestamp":1638782346349,"user_tz":-540,"elapsed":308,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"68b8797d-1c8f-4547-e4b8-1497a287018e"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'mystery', 'and', 'its', 'solution', 'was', 'a', 'great', 'noir', 'conceit.', 'i', 'do', 'have', 'some', 'questions', 'though,', 'maybe', 'i', \"wasn't\", 'paying', 'enough', 'attention.<br', '/><br', '/>who', 'killed', 'the', 'neighbor', 'and', 'why?', 'who', 'killed', 'the', 'replacement', 'girl', 'and', 'why?<br', '/><br', '/>and', 'some', 'minor', 'quibbles,', 'they', 'should', 'have', 'shown', 'the', 'stopoff', 'at', 'the', 'hotel', 'for', 'the', 'switch.', 'not', 'that', 'they', 'should', 'have', 'shown', 'the', 'switch,', 'but', 'they', 'should', 'have', 'shown', 'jim', 'and', 'the', 'girl', 'going', 'in', 'the', 'hotel,', 'jim', 'going', 'to', 'the', 'bathroom,', 'coming', 'out', 'and', 'being', 'told', 'by', 'the', 'bartender', 'that', 'his', 'girlfriend', 'went', 'to', 'the', 'car', 'without', 'him.<br', '/><br', '/>then,', 'jim', 'getting', 'back', 'in', 'the', 'car', 'and', 'seeing', 'the', 'sleeping', 'woman,', 'and', 'little', 'girl', 'in', 'his', 'back', 'seat.<br', '/><br', '/>this', 'would', 'have', 'given', 'the', 'viewer', 'a', 'sporting', 'chance', 'at', 'figuring', 'out', 'the', 'solution.<br', '/><br', '/>i', 'wish', 'i', 'taped', 'it', 'though,', \"i'd\", 'like', 'to', 'see', 'it', 'again.']\n","tensor([1], device='cuda:0')\n"]}]}]}