{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L16_Convolutional Neural Network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqX4Lgr9Y81j493k2ApT3j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Fy2_q1yA_eY2"},"source":["# Convolutional Neural Network\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"kFWSw3mPzCd3"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"ePyjL-fEA4As","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634177984946,"user_tz":-540,"elapsed":26554,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"7e50645b-0fde-45dd-d4bf-9b2ca3563639"},"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fc3da535b90>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"SH2RX5pEBB0H"},"source":["### 1 CNN model\n","* Input (입력의 형태)\n","  + Input type: torch.Tensor\n","  + Input shape: (N x C x H x W) \n","    - N: Batch size, C: # of channels, H: height, W: width\n","  + (?, 1, 28, 28)\n","    - 여러장의, 흑백, 28x28 size의 이미지라고 가정하자\n","* Layer 설계\n","  + Layer 1\n","    - Conv2d >> C: 32, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n","    - ReLU\n","    - MaxPool >> Kernel size: 2, Stride: 2\n","    - 입-출력 (?, 1, 28, 28) >> (?, 32, 14, 14)\n","  + Layer 2\n","    - Conv2d >> C: 64, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n","    - ReLU\n","    - MaxPool >> Kernel size: 2, Stride: 2\n","    - 입-출력 (?, 32, 14, 14) >> (?, 64, 7, 7)\n","  + Layer 3\n","    - Linear >> input: 7x7x64 output: 10\n","    - Softmax"]},{"cell_type":"code","metadata":{"id":"HL2ZwVjWBCw7"},"source":["class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # L1 Input shape=(?, 1, 28, 28)\n","        #    Conv     -> (?, 32, 28, 28)\n","        #    Pool     -> (?, 32, 14, 14)\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","        # L2 Input shape=(?, 32, 14, 14)\n","        #    Conv      ->(?, 64, 14, 14)\n","        #    Pool      ->(?, 64, 7, 7)\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","        # L3 Linear 64x7x7 inputs -> 10 outputs\n","        self.fc = torch.nn.Linear(64*7*7, 10, bias=True)\n","        torch.nn.init.xavier_uniform_(self.fc.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)   # Flatten them for FC\n","        out = self.fc(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hc6TPzluWB1M"},"source":["### 2 Assignment\n","### 다음과 같은 CNN 모델을 작성해보자\n","* Input \n","  + Input type: torch.Tensor\n","  + Input shape: (?, 1, 28, 28)\n","    - 여러장의, 흑백, 28x28 size의 이미지라고 가정하자\n","* Layers\n","  + Layer 1\n","    - Conv2d >> C: 32, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n","    - ReLU\n","    - MaxPool >> Kernel size: 2, Stride: 2\n","    - 입-출력 (?, 1, 28, 28) >> (?, 32, 14, 14)\n","  + Layer 2\n","    - Conv2d >> C: 64, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n","    - ReLU\n","    - MaxPool >> Kernel size: 2, Stride: 2\n","    - 입-출력 (?, 32, 14, 14) >> (?, 64, 7, 7)\n","  + Layer 3\n","    - Conv2d >> C: 128, Kernel size (필터 크기): 3, Stride: 1, Padding: 1\n","    - ReLU\n","    - MaxPool >> Kernel size: 2, Stride: 2, Padding: 1\n","    - 입-출력 (?, 64, 7, 7) >> (?, 128, 4, 4)\n","  + Layer 4\n","    - Linear >> input: 4x4x128 output: 625\n","    - ReLU\n","    - Dropout\n","    - 입-출력 (4x4x128) >> (625)\n","  + Layer 5\n","    - Linear >> input: 625 output: 10\n","    - Softmax (pytorch의 Cross Entropy Loss 함수를 사용하는 것을 감안한다)\n","    \n"]}]}